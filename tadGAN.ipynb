{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import keras from tensorflow\n",
    "import os\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-08 11:48:52.849397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-08 11:48:52.849417: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>function for wasserstein loss</h1>\n",
    "- described in the [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n",
    "<br>\n",
    "- implemented in [tadGAN](https://arxiv.org/pdf/2009.07769.pdf)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def _wasserstein_loss(y_true, y_pred):\n",
    "    return tf.keras.backend.mean(y_true * y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Define all of the input shapes and parameters</h1>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seq_len = 100 # sequence length must always be even\n",
    "ts_input_shape: Tuple[int] = (100, 1),#this is for univariant data , change the shape accorindly ex for multivariant data change to (100,num_features)\n",
    "latent_dim: int = 20, #latent dimension where encoder and decoder will be trained\n",
    "gradient_penalty_weight: int = 10, #gradient penelty weight for wasserstein loss\n",
    "n_iterations_critic: int = 5, #number of iterations for training the critic per iter for encoder and decoder\n",
    "\n",
    "# sub network hyper parameters\n",
    "encoder_lstm_units: int = 100, # number of units in encoder LSTM\n",
    "generator_lstm_units: int = 100, # number of units in generator LSTM\n",
    "generator_output_activation: str = \"tanh\", # activation function for generator output\n",
    "critic_x_cnn_blocks: int = 4, # number of convolutional blocks in critic x\n",
    "critic_x_cnn_filters: int = 64, # number of filters in each convolutional block in critic x\n",
    "critic_z_dense_units: int = 100, # number of units in critic z dense layer\n",
    "\n",
    "log_all_losses: bool = True, \n",
    "print_model_summaries: bool = True "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an encoder layer </h1>\n",
    "    - Build the Encoder subnetwork for the GAN. This model learns the compressed representation of the input and transforms the timesries sequence into the latent space\n",
    "    </br>\n",
    "    - The encoder uses a single layer BI-LSTM network to learn the compressed representation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_encoder(input_shape: Tuple[int, int, int], lstm_units:int = 100, latent_dim:int=20)->tf.keras.Model:\n",
    "    \"\"\"\n",
    "        The number of LSTM units can be adjusted.\n",
    "\n",
    "        :param lstm_units: Number of LSTM units that could be used for the time series encoding\n",
    "\n",
    "        :input_shape: Tuple of input shape (batch_size, len_sequence, num_features)\n",
    "\n",
    "        :return: Encoder model\n",
    "    \"\"\"\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=input_shape , name=\"encoder_input\")\n",
    "    #create a bi-directional LSTM layer\n",
    "    encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True))(input)\n",
    "    encoder = tf.layers.Flatten()(encoder)\n",
    "    encoder = tf.keras.layers.Dense(units=latent_dim , name=\"latent_encoding\")(encoder)\n",
    "    endoer = tf.keras.layers.Reshape(target_shape=(latent_dim , 1))(encoder)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=endoer, name=\"encoder\")\n",
    "    return model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an generator layer </h1>\n",
    "    - Build the generator subnetwork for the GAN. This recreates the timeseries sequence from the latent space\n",
    "    </br>\n",
    "    - The generator  uses a double  layer BI-LSTM network to recreate the timeseries data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_generator(latent_shape: Tuple[int , int], lstm_units:int = 64, activation_function:str=\"tanh\")->tf.keras.Model:\n",
    "    \"\"\"\n",
    "        The number of LSTM units can be adjusted.\n",
    "\n",
    "        :param lstm_units: Number of LSTM units that could be used for the time series generation\n",
    "\n",
    "        :param latent_shape: Shape of the latent encoding\n",
    "\n",
    "        :param activation_function: final activation layer for the generator \n",
    "\n",
    "        :return: Generator model\n",
    "    \"\"\"\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=latent_shape, name=\"generator_input\")\n",
    "    flatten = tf.keras.layers.Flatten()(input)\n",
    "\n",
    "    #first layer should be half the size of the sequence\n",
    "    half_seq_length = seq_len // 2\n",
    "    decoded = tf.keras.layers.Dense(units=half_seq_length)(decoded)\n",
    "    decoded = tf.keras.layers.Reshape(target_shape=(half_seq_length, 1))(decoded)  \n",
    "\n",
    "    # generate a new timeseries using two ltsm layers that have 64 hidden units with upsampling  between them\n",
    "    decoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True, dropout=0.2 , recurrent_dropout=0.2), merge_mode=\"concat\")(decoded)\n",
    "    decoder = tf.keras.layers.UpSampling1D(size=2)(decoder)\n",
    "    decoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True, dropout=0.2 , recurrent_dropout=0.2), merge_mode=\"concat\")(decoder)\n",
    "\n",
    "    #rebuild the original shape of the time series for all signals\n",
    "    decoder = tf.keras.layer.TimeDistributed(tf.keras.layers.Dense(units=1))(decoder)\n",
    "    decoder = tf.keras.layer.activation(activation_function)(decoder)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input, outputs=decoder, name=\"generator\")\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an critic_x  layer </h1>\n",
    "    - Build the critic subnetwork for the GAN. This distinguishes between the timeseries sequence and the generated sequence.\n",
    "    </br>\n",
    "    - The critic uses sequence of 1d convolutional layers to distinguish between the timeseries and generated sequence. and finally a fully connected layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_critic_x(input_shape: Tuple[int , int , int] ,num_filters: int = 64, num_cnn_blocks: int = 4)->tf.keras.Model:\n",
    "    \"\"\"\n",
    "        Builds the critic model for the critic_x\n",
    "\n",
    "        :param num_filters: Number of filters in each convolutional block\n",
    "\n",
    "        :param num_cnn_blocks: Number of convolutional blocks in the critic\n",
    "\n",
    "        :return: Critic model\n",
    "    \"\"\"\n",
    "    input = tf.keras.layers.Input(shape=(seq_len, 1), name=\"critic_x_input\")\n",
    "    #create a convolutional layer with num_filters filters\n",
    "    conv = tf.keras.layers.Conv1D(filters=num_filters, kernel_size=5)(input)\n",
    "    conv = tf.keras.layers.LeakyReLU(alpha=0.2)(conv)\n",
    "    conv = tf.keras.layers.Dropout(0.25)(conv)\n",
    "\n",
    "    for i in range(num_cnn_blocks):\n",
    "        conv = tf.keras.layers.Conv1D(filters=num_filters, kernel_size=5, padding=\"same\")(conv)\n",
    "        conv = tf.keras.layers.LeakyReLU(alpha=0.2)(conv)\n",
    "        conv = tf.keras.layers.Dropout(0.25)(conv)\n",
    "    \n",
    "    #flatten the output and create a dense output layer\n",
    "    conv = tf.keras.layers.Flatten()(conv)\n",
    "    conv = tf.keras.layers.Dense(units=1)(conv)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=conv, name=\"critic_x\")\n",
    "    return model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an critic_z layer </h1>\n",
    "    - Build the critic subnetwork for the GAN. This distinguishes between the timeseries sequence and the generated sequence.\n",
    "    </br>\n",
    "    - The critic uses two fully connected layers to  distinguish between the real encoded sequence and fake encoding sequence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_critic_z(latent_space_dim: Tuple[int , int] ,num_dense_units: int = 100)->tf.keras.Model:\n",
    "    \"\"\"\n",
    "        Builds the critic model for critic_z\n",
    "\n",
    "        :param latent_space_dim: shaoe of the latent space\n",
    "\n",
    "        :param num_dense_units: Number of units in the dense layer\n",
    "\n",
    "        :return: Critic model\n",
    "    \"\"\"\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=latent_space_dim, name=\"critic_z_input\")\n",
    "\n",
    "    dense = tf.keras.layers.Flatten()(input)\n",
    "    dense = tf.keras.layers.Dense(units=num_dense_units)(input)\n",
    "    dense = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\n",
    "    dense = tf.keras.layers.Dropout(0.25)(dense)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(units=num_dense_units)(dense)\n",
    "    dense = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\n",
    "    dense = tf.keras.layers.Dropout(0.25)(dense)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(units=1)(dense)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=dense, name=\"critic_z\")\n",
    "    return model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>calculate gradient penalty </h1>\n",
    "    <h2></h2>\n",
    "    - The gradient penalty is used to ensure that the critic is not too sure about the discriminator's ability to distinguish between the real and fake sequences.\n",
    "    <br>\n",
    "    - This reguralizations is used to reduce the risk of gradient exploding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def critic_x_gradient_penalty(critic_x , batch_size, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the gradient penalty.\n",
    "    \"\"\"\n",
    "    alpha = tf.keras.backend.random_uniform((batch_size, 1, 1))\n",
    "    interpolated = (alpha * y_true) + ((1 - alpha) * y_pred)\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = critic_x(interpolated)\n",
    "\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "\n",
    "    return gp\n",
    "\n",
    "@tf.function\n",
    "def critic_z_gradient_penalty(critic_z, batch_size, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the gradient penalty.\n",
    "    \"\"\"\n",
    "    alpha = tf.keras.backend.random_uniform((batch_size, 1, 1))\n",
    "    interpolated = (alpha * y_true) + ((1 - alpha) * y_pred)\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = critic_z(interpolated)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
    "    gp = tf.reduce_mean((1.0 - norm) ** 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Calculate loss function </h1>\n",
    "- do loss calculations for the critics , encoder and generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def critic_x_loss(generator,critic_x, critic_x_loss_fn ,gradient_penelty_weight ,   x_mb, z, valid, fake, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Do a step forward and calculate the loss on the critic x model\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :param critic_x: Critic x model\n",
    "    :param critic_x_loss_fn: Critic x loss function\n",
    "    :param gradient_penalty_weight: Weight of the gradient penalty\n",
    "    :param x_mb: Minibatch of input data\n",
    "    :param z: Minibatch of random noise\n",
    "    :param valid: Ground truth vector for valid samples\n",
    "    :param fake: Ground truth vector for fake samples\n",
    "    :param mini_batch_size:\n",
    "\n",
    "    :return: A tuple containing the total loss and the three single losses\n",
    "    \"\"\"\n",
    "    # Do a step forward on critic x model and collect gradients\n",
    "    x_ = generator(z)\n",
    "    fake_x = critic_x(x_)\n",
    "    valid_x = critic_x(x_mb)\n",
    "\n",
    "    # Calculate critic x loss\n",
    "    critic_x_valid_cost = critic_x_loss_fn(y_true=valid, y_pred=valid_x)\n",
    "    critic_x_fake_cost = critic_x_loss_fn(y_true=fake, y_pred=fake_x)\n",
    "    # TODO: [SMe] Is the mini_batch size still required?\n",
    "    critic_x_gradient_penalty = critic_x_gradient_penalty(mini_batch_size, x_mb, x_)\n",
    "    critic_x_total_loss = critic_x_valid_cost + critic_x_fake_cost + (critic_x_gradient_penalty * gradient_penelty_weight)\n",
    "\n",
    "    return critic_x_total_loss, critic_x_valid_cost, critic_x_fake_cost, critic_x_gradient_penalty\n",
    "\n",
    "@tf.function\n",
    "def critic_z_loss(encoder , critic_z, critic_z_loss_fn, gradient_penelty_weight,x_mb, z, valid, fake, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Do a step forward and calculate the loss on the critic z model\n",
    "\n",
    "    :param encoder: Encoder model\n",
    "    :param critic_z: Critic z model\n",
    "    :param critic_z_loss_fn: Critic z loss function\n",
    "    :param gradient_penalty_weight: Weight of the gradient penalty\n",
    "    :param x_mb: Minibatch of input data\n",
    "    :param z: Minibatch of random noise\n",
    "    :param valid: Ground truth vector for valid samples\n",
    "    :param fake: Ground truth vector for fake samples\n",
    "    :param mini_batch_size:\n",
    "\n",
    "    :return: A tuple containing the total loss and the three single losses\n",
    "    \"\"\"\n",
    "    # Do a step forward on critic z model and collect gradients\n",
    "    z_ = encoder(x_mb)\n",
    "    fake_z = critic_z(z_)\n",
    "    valid_z = critic_z(z)\n",
    "\n",
    "    # Calculate critic z loss\n",
    "    critic_z_valid_cost = critic_z_loss_fn(y_true=valid, y_pred=valid_z)\n",
    "    critic_z_fake_cost = critic_z_loss_fn(y_true=fake, y_pred=fake_z)\n",
    "    critic_z_gradient_penalty = critic_z_gradient_penalty(mini_batch_size, z, z_)\n",
    "    critic_z_total_loss = critic_z_valid_cost + critic_z_fake_cost + (critic_z_gradient_penalty * gradient_penelty_weight)\n",
    "    return critic_z_total_loss, critic_z_valid_cost, critic_z_fake_cost, critic_z_gradient_penalty\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def encoder_generator_loss(generator , encoder , critic_x , critic_z , encoder_generator_loss_fn , x_mb, z, valid):\n",
    "    \"\"\"\n",
    "    Do a step forward and calculate the loss on the encoder-generator model\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :param encoder: Encoder model\n",
    "    :param critic_x: Critic x model\n",
    "    :param critic_z: Critic z model\n",
    "    :param encoder_generator_loss_fn: Encoder-generator loss function\n",
    "    :param x_mb: Minibatch of input data\n",
    "    :param z: Minibatch of random noise\n",
    "    :param valid: Ground truth vector for valid samples\n",
    "\n",
    "    :return: A tuple containing the total loss and the three single losses\n",
    "    \"\"\"\n",
    "    # Do a step forward on the encoder generator model\n",
    "    x_gen_ = generator(z)\n",
    "    fake_gen_x = critic_x(x_gen_)\n",
    "\n",
    "    z_gen_ = encoder(x_mb)\n",
    "    x_gen_rec = generator(z_gen_)\n",
    "    fake_gen_z = critic_z(z_gen_)\n",
    "\n",
    "    # Calculate encoder generator loss\n",
    "    encoder_generator_fake_gen_x_cost = encoder_generator_loss_fn(y_true=valid, y_pred=fake_gen_x)\n",
    "    encoder_generator_fake_gen_z_cost = encoder_generator_loss_fn(y_true=valid, y_pred=fake_gen_z)\n",
    "\n",
    "    # Use simple MSE as reconstruction error\n",
    "    general_reconstruction_cost = tf.reduce_mean(tf.square((x_mb - x_gen_rec)))\n",
    "    encoder_generator_total_loss = encoder_generator_fake_gen_x_cost + encoder_generator_fake_gen_z_cost + (10.0 * general_reconstruction_cost)\n",
    "\n",
    "    return encoder_generator_total_loss, encoder_generator_fake_gen_x_cost, encoder_generator_fake_gen_z_cost, general_reconstruction_cost\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Training step for the model </h1>\n",
    "- do training step for the critics , encoder and generator\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def train_step(input, n_iterations_critic,encoder, generator,critic_x , critic_z ,  critic_x_loss, critic_z_loss, encoder_generator_loss)->dict:\n",
    "    \"\"\"\n",
    "    Custom training step for this Subclassing API Keras model.\n",
    "    The shape should be (n_iterations_critic * batch size, n_channels) because the critic networks are trained\n",
    "    multiple times over the encoder-generator network.\n",
    "\n",
    "    :param X: Group of mini batches that are used to train the critics and the encoder-generator network\n",
    "                Shape: (batch_size, signal_length, n_channels)\n",
    "    :param n_iterations_critic: Number of iterations to train the critic network\n",
    "    :param critic_x_loss: Critic x loss function\n",
    "    :param critic_z_loss: Critic z loss function\n",
    "    :param encoder_generator_loss: Encoder-generator loss function\n",
    "    :param critic_x_optimizer: Critic x optimizer\n",
    "    :param critic_z_optimizer: Critic z optimizer\n",
    "\n",
    "\n",
    "    :return: Sub-model losses as los dict\n",
    "    \"\"\"\n",
    "    # Get the input data\n",
    "    X = input[0]\n",
    "    batch_size = X.shape[0]\n",
    "    minibatch_size = batch_size//n_iterations_critic\n",
    "    critic_x_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    critic_z_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    encoder_generator_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    encoder_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    critic_x_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    critic_z_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "    #prepare ground truth data\n",
    "    valid = tf.ones((minibatch_size, 1))\n",
    "    fake = tf.ones((minibatch_size, 1))\n",
    "\n",
    "    critic_x_loss_steps = []\n",
    "    critic_z_loss_steps = []\n",
    "\n",
    "    for critic_train_steps in range(n_iterations_critic):\n",
    "        z = tf.random.normal((minibatch_size, latent_dim, 1))\n",
    "        x_mb = X[critic_train_steps * minibatch_size:(critic_train_steps + 1) * minibatch_size]\n",
    "\n",
    "        #optimize step on critic x model\n",
    "        with tf.GradientTape as tape:\n",
    "            _critic_x_losses = critic_x_loss(encoder, generator, critic_x, critic_x_loss_fn, x_mb, z, valid, fake, minibatch_size)\n",
    "        \n",
    "        #backward step on critic x model\n",
    "        critic_x_gradient = tape.gradient(_critic_x_losses[0], critic_x.trainable_variables)\n",
    "        critic_x_optimizer.apply_gradients(zip(critic_x_gradient, critic_x.trainable_variables))\n",
    "\n",
    "        _critic_x_losses = np.array(_critic_x_losses)\n",
    "        critic_x_loss_steps.append(_critic_x_losses)\n",
    "\n",
    "\n",
    "        #optimize step on critic z model\n",
    "        with tf.GradientTape as tape:\n",
    "            _critic_z_losses = critic_z_loss(encoder , critic_z , critic_z_loss_fn, gradient_penalty_weight , x_mb, z, valid, fake, minibatch_size)\n",
    "        \n",
    "        #backward step on critic z model\n",
    "        critic_z_gradient = tape.gradient(_critic_z_losses[0], critic_z.trainable_variables)\n",
    "        critic_z_optimizer.apply_gradients(zip(critic_z_gradient, critic_z.trainable_variables))\n",
    "\n",
    "        _critic_z_losses = np.array(_critic_z_losses)\n",
    "        critic_z_loss_steps.append(_critic_z_losses)\n",
    "    \n",
    "    #optimize step on encoder-generator model\n",
    "    with tf.GradientTape as tape:\n",
    "        #step forward for the generator model\n",
    "        _encoder_generator_losses = encoder_generator_loss(generator, encoder, critic_x, critic_z, encoder_generator_loss_fn, X, z, valid)\n",
    "    \n",
    "    #backward step on encoder-generator model\n",
    "    encoder_generator_gradient = tape.gradient(_encoder_generator_losses, encoder.trainable_variables +  generator.trainable_variables)\n",
    "    encoder_generator_optimizer.apply_gradients(zip(encoder_generator_gradient, encoder.trainable_variables + generator.trainable_variables))\n",
    "    \n",
    "\n",
    "    critic_x_losses = np.mean(np.array(critic_x_loss_steps), axis=0)\n",
    "    critic_z_losses = np.mean(np.array(critic_z_loss_steps), axis=0)\n",
    "    encoder_generator_losses = np.array(_encoder_generator_losses)\n",
    "\n",
    "    if log_all_losses:\n",
    "        loss_dict = {\n",
    "            \"Cx_total\": critic_x_losses[0],\n",
    "            \"Cx_valid\": critic_x_losses[1],\n",
    "            \"Cx_fake\": critic_x_losses[2],\n",
    "            \"Cx_gp_penalty\": critic_x_losses[3],\n",
    "\n",
    "            \"Cz_total\": critic_z_losses[0],\n",
    "            \"Cz_valid\": critic_z_losses[1],\n",
    "            \"Cz_fake\": critic_z_losses[2],\n",
    "            \"Cz_gp_penalty\": critic_z_losses[3],\n",
    "\n",
    "            \"EG_total\": encoder_generator_losses[0],\n",
    "            \"EG_fake_gen_x\": encoder_generator_losses[1],\n",
    "            \"EG_fake_gen_z\": encoder_generator_losses[2],\n",
    "            \"G_rec\": encoder_generator_losses[3],\n",
    "        }\n",
    "    else:\n",
    "        loss_dict = {\n",
    "            \"Cx_total\": critic_x_losses[0],\n",
    "            \"Cz_total\": critic_z_losses[0],\n",
    "            \"EG_total\": encoder_generator_losses[0]\n",
    "        }\n",
    "\n",
    "    return loss_dict\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def test_step(input,encoder , generator , critic_x , critic_z , critic_x_loss, critic_z_loss, encoder_generator_loss, gradient_penalty_weight):\n",
    "    \"\"\"\n",
    "    \n",
    "    test step for model\n",
    "    overrides model.evaluate\n",
    "\n",
    "    :param input: minibatch of the time series signals (batce_size , signal_length , n_channels)\n",
    "    :param critic_x_loss: loss function for critic x\n",
    "    :param critic_z_loss: loss function for critic z\n",
    "    :param encoder_generator_loss: loss function for encoder and generator\n",
    "    :param graident_penalty_weight: penalty weight for gradient\n",
    "\n",
    "    :return: sub-model losses as loss dict\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    input = input[0]\n",
    "    batch_size = input.shape[0]\n",
    "\n",
    "    fake = tf.ones((batch_size , 1))\n",
    "    valid = tf.ones((batch_size , 1))\n",
    "\n",
    "\n",
    "    critic_x_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    critic_z_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    encoder_generator_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    encoder_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    critic_x_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    critic_z_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    z = tf.random.normal(shape=(batch_size , latent_dim , 1))\n",
    "\n",
    "    critic_x_losses = critic_x_loss(generator,critic_x, critic_x_loss_fn ,gradient_penalty_weight , input , z, valid, fake, batch_size)\n",
    "    critic_z_losses = critic_z_loss(encoder , critic_z, critic_z_loss_fn, gradient_penalty_weight, input , z, valid, fake, batch_size)\n",
    "    encoder_generator_losses = encoder_generator_loss(generator , encoder , critic_x , critic_z , encoder_generator_loss_fn , input , z, valid)\n",
    "\n",
    "\n",
    "    if log_all_losses:\n",
    "        loss_dict = {\n",
    "            \"Cx_total\": critic_x_losses[0],\n",
    "            \"Cx_valid\": critic_x_losses[1],\n",
    "            \"Cx_fake\": critic_x_losses[2],\n",
    "            \"Cx_gp_penalty\": critic_x_losses[3],\n",
    "\n",
    "            \"Cz_total\": critic_z_losses[0],\n",
    "            \"Cz_valid\": critic_z_losses[1],\n",
    "            \"Cz_fake\": critic_z_losses[2],\n",
    "            \"Cz_gp_penalty\": critic_z_losses[3],\n",
    "\n",
    "            \"EG_total\": encoder_generator_losses[0],\n",
    "            \"EG_fake_gen_x\": encoder_generator_losses[1],\n",
    "            \"EG_fake_gen_z\": encoder_generator_losses[2],\n",
    "            \"G_rec\": encoder_generator_losses[3],\n",
    "        }\n",
    "    else:\n",
    "        loss_dict = {\n",
    "            \"Cx_total\": critic_x_losses[0],\n",
    "            \"Cz_total\": critic_z_losses[0],\n",
    "            \"EG_total\": encoder_generator_losses[0]\n",
    "        }\n",
    "\n",
    "    return loss_dict\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "7df55eb6eb445687b1bb3d527eb3c0b7cd1b87e7f83fbb3267f7617449b0ccb8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}