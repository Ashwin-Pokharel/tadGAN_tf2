{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import keras from tensorflow\r\n",
    "import os\r\n",
    "from typing import Tuple\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "from tadgan import TadGAN\r\n",
    "from tqdm import trange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>function for wasserstein loss</h1>\n",
    "- described in the [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n",
    "<br>\n",
    "- implemented in [tadGAN](https://arxiv.org/pdf/2009.07769.pdf)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def _wasserstein_loss(y_true, y_pred):\r\n",
    "    return tf.keras.backend.mean(y_true * y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Define all of the input shapes and parameters</h1>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "seq_len = 100 # sequence length must always be even\r\n",
    "ts_input_shape: Tuple[int] = (seq_len, 8)#this is for univariant data , change the shape accorindly ex for multivariant data change to (100,num_features)\r\n",
    "latent_dim: int = 20 #latent dimension where encoder and decoder will be trained\r\n",
    "gradient_penalty_weight: int = 10#gradient penelty weight for wasserstein loss\r\n",
    "n_iterations_critic: int = 5#number of iterations for training the critic per iter for encoder and decoder\r\n",
    "\r\n",
    "# sub network hyper parameters\r\n",
    "encoder_lstm_units: int = 100 # number of units in encoder LSTM\r\n",
    "generator_lstm_units: int = 100 # number of units in generator LSTM\r\n",
    "generator_output_activation: str = \"tanh\" # activation function for generator output\r\n",
    "critic_x_cnn_blocks: int = 4 # number of convolutional blocks in critic x\r\n",
    "critic_x_cnn_filters: int = 64 # number of filters in each convolutional block in critic x\r\n",
    "critic_z_dense_units: int = 100 # number of units in critic z dense layer\r\n",
    "\r\n",
    "log_all_losses: bool = True\r\n",
    "print_model_summaries: bool = True "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an encoder layer </h1>\n",
    "    - Build the Encoder subnetwork for the GAN. This model learns the compressed representation of the input and transforms the timesries sequence into the latent space\n",
    "    </br>\n",
    "    - The encoder uses a single layer BI-LSTM network to learn the compressed representation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def generate_encoder(input_shape: Tuple[int]=(100,1), lstm_units:int = 100, latent_dim:int=20)->tf.keras.Model:\r\n",
    "    \"\"\"\r\n",
    "        The number of LSTM units can be adjusted.\r\n",
    "\r\n",
    "        :param lstm_units: Number of LSTM units that could be used for the time series encoding\r\n",
    "\r\n",
    "        :input_shape: Tuple of input shape (batch_size, len_sequence, num_features)\r\n",
    "\r\n",
    "        :return: Encoder model\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    input = tf.keras.layers.Input(shape=input_shape , name=\"encoder_input\")\r\n",
    "    #create a bi-directional LSTM layer\r\n",
    "    encoded = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=lstm_units, return_sequences=True))(input)\r\n",
    "    encoded = tf.keras.layers.Flatten()(encoded)\r\n",
    "    encoded = tf.keras.layers.Dense(units=latent_dim, name=\"latent_encoding\")(encoded)\r\n",
    "    encoded = tf.keras.layers.Reshape(target_shape=(latent_dim, 1), name='output_encoder')(encoded)\r\n",
    "\r\n",
    "    model = tf.keras.Model(inputs=input, outputs=encoded, name=\"encoder_model\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an generator layer </h1>\n",
    "    - Build the generator subnetwork for the GAN. This recreates the timeseries sequence from the latent space\n",
    "    </br>\n",
    "    - The generator  uses a double  layer BI-LSTM network to recreate the timeseries data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def generate_generator(latent_shape: Tuple[int], lstm_units:int = 64, activation_function:str=\"tanh\") -> tf.keras.Model:\r\n",
    "    \"\"\"\r\n",
    "        The number of LSTM units can be adjusted.\r\n",
    "\r\n",
    "        :param lstm_units: Number of LSTM units that could be used for the time series generation\r\n",
    "\r\n",
    "        :param latent_shape: Shape of the latent encoding\r\n",
    "\r\n",
    "        :param activation_function: final activation layer for the generator \r\n",
    "\r\n",
    "        :return: Generator model\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    input = tf.keras.layers.Input(shape=latent_shape, name=\"generator_input\")\r\n",
    "    decoded = tf.keras.layers.Flatten()(input)\r\n",
    "\r\n",
    "    #first layer should be half the size of the sequence\r\n",
    "    half_seq_length = seq_len // 2\r\n",
    "    decoded = tf.keras.layers.Dense(units=half_seq_length)(decoded)\r\n",
    "    decoded = tf.keras.layers.Reshape(target_shape=(half_seq_length, 1))(decoded)  \r\n",
    "\r\n",
    "    # generate a new timeseries using two ltsm layers that have 64 hidden units with upsampling  between them\r\n",
    "    decoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True, dropout=0.2 , recurrent_dropout=0.2), merge_mode=\"concat\")(decoded)\r\n",
    "    decoder = tf.keras.layers.UpSampling1D(size=2)(decoder)\r\n",
    "    decoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True, dropout=0.2 , recurrent_dropout=0.2), merge_mode=\"concat\")(decoder)\r\n",
    "\r\n",
    "    #rebuild the original shape of the time series for all signals\r\n",
    "    decoder = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1))(decoder)\r\n",
    "    decoder = tf.keras.layers.Activation(activation_function)(decoder)\r\n",
    "    return tf.keras.Model(inputs=input, outputs=decoder, name=\"generator\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an critic_x  layer </h1>\n",
    "    - Build the critic subnetwork for the GAN. This distinguishes between the timeseries sequence and the generated sequence.\n",
    "    </br>\n",
    "    - The critic uses sequence of 1d convolutional layers to distinguish between the timeseries and generated sequence. and finally a fully connected layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def build_critic_x(input_shape ,num_filters: int = 64, num_cnn_blocks: int = 4) -> tf.keras.Model:\r\n",
    "    \"\"\"\r\n",
    "        Builds the critic model for the critic_x\r\n",
    "\r\n",
    "        :param num_filters: Number of filters in each convolutional block\r\n",
    "\r\n",
    "        :param num_cnn_blocks: Number of convolutional blocks in the critic\r\n",
    "\r\n",
    "        :return: Critic model\r\n",
    "    \"\"\"\r\n",
    "    input = tf.keras.layers.Input(shape=input_shape, name=\"critic_x_input\")\r\n",
    "    #create a convolutional layer with num_filters filters\r\n",
    "    conv = tf.keras.layers.Conv1D(filters=num_filters, kernel_size=5)(input)\r\n",
    "    conv = tf.keras.layers.LeakyReLU(alpha=0.2)(conv)\r\n",
    "    conv = tf.keras.layers.Dropout(0.25)(conv)\r\n",
    "\r\n",
    "    for _ in range(num_cnn_blocks):\r\n",
    "        conv = tf.keras.layers.Conv1D(filters=num_filters, kernel_size=5, padding=\"same\")(conv)\r\n",
    "        conv = tf.keras.layers.LeakyReLU(alpha=0.2)(conv)\r\n",
    "        conv = tf.keras.layers.Dropout(0.25)(conv)\r\n",
    "\r\n",
    "    #flatten the output and create a dense output layer\r\n",
    "    conv = tf.keras.layers.Flatten()(conv)\r\n",
    "    conv = tf.keras.layers.Dense(units=1)(conv)\r\n",
    "\r\n",
    "    return tf.keras.Model(inputs=input, outputs=conv, name=\"critic_x\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Make an critic_z layer </h1>\n",
    "    - Build the critic subnetwork for the GAN. This distinguishes between the timeseries sequence and the generated sequence.\n",
    "    </br>\n",
    "    - The critic uses two fully connected layers to  distinguish between the real encoded sequence and fake encoding sequence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def build_critic_z(latent_space_dim: Tuple[int , int] ,num_dense_units: int = 100)->tf.keras.Model:\r\n",
    "    \"\"\"\r\n",
    "        Builds the critic model for critic_z\r\n",
    "\r\n",
    "        :param latent_space_dim: shaoe of the latent space\r\n",
    "\r\n",
    "        :param num_dense_units: Number of units in the dense layer\r\n",
    "\r\n",
    "        :return: Critic model\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    input = tf.keras.layers.Input(shape=latent_space_dim, name=\"critic_z_input\")\r\n",
    "\r\n",
    "    dense = tf.keras.layers.Flatten()(input)\r\n",
    "    dense = tf.keras.layers.Dense(units=num_dense_units)(input)\r\n",
    "    dense = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\r\n",
    "    dense = tf.keras.layers.Dropout(0.25)(dense)\r\n",
    "\r\n",
    "    dense = tf.keras.layers.Dense(units=num_dense_units)(dense)\r\n",
    "    dense = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\r\n",
    "    dense = tf.keras.layers.Dropout(0.25)(dense)\r\n",
    "    \r\n",
    "    dense = tf.keras.layers.Dense(units=1)(dense)\r\n",
    "\r\n",
    "    model = tf.keras.Model(inputs=input, outputs=dense, name=\"critic_z\")\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>calculate gradient penalty </h1>\n",
    "    <h2></h2>\n",
    "    - The gradient penalty is used to ensure that the critic is not too sure about the discriminator's ability to distinguish between the real and fake sequences.\n",
    "    <br>\n",
    "    - This reguralizations is used to reduce the risk of gradient exploding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "@tf.function\r\n",
    "def critic_x_gradient_penalty(critic_x , batch_size, y_true, y_pred):\r\n",
    "    \"\"\"\r\n",
    "    Calculates the gradient penalty.\r\n",
    "    \"\"\"\r\n",
    "    alpha = tf.keras.backend.random_uniform((batch_size, 1, 1))\r\n",
    "    interpolated = (alpha * y_true) + ((1 - alpha) * y_pred)\r\n",
    "\r\n",
    "    with tf.GradientTape() as gp_tape:\r\n",
    "        gp_tape.watch(interpolated)\r\n",
    "        # 1. Get the discriminator output for this interpolated image.\r\n",
    "        pred = critic_x(interpolated)\r\n",
    "\r\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\r\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\r\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\r\n",
    "\r\n",
    "    return gp\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def critic_z_gradient_penalty(critic_z, batch_size, y_true, y_pred):\r\n",
    "    \"\"\"\r\n",
    "    Calculates the gradient penalty.\r\n",
    "    \"\"\"\r\n",
    "    alpha = tf.keras.backend.random_uniform((batch_size, 1, 1))\r\n",
    "    interpolated = (alpha * y_true) + ((1 - alpha) * y_pred)\r\n",
    "\r\n",
    "    with tf.GradientTape() as gp_tape:\r\n",
    "        gp_tape.watch(interpolated)\r\n",
    "        # 1. Get the discriminator output for this interpolated image.\r\n",
    "        pred = critic_z(interpolated)\r\n",
    "\r\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\r\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\r\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\r\n",
    "    gp = tf.reduce_mean((1.0 - norm) ** 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Calculate loss function </h1>\n",
    "- do loss calculations for the critics , encoder and generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "@tf.function\r\n",
    "def critic_x_loss(generator,critic_x, critic_x_loss_fn ,gradient_penelty_weight ,   x_mb, z, valid, fake, mini_batch_size):\r\n",
    "    \"\"\"\r\n",
    "    Do a step forward and calculate the loss on the critic x model\r\n",
    "\r\n",
    "    :param generator: Generator model\r\n",
    "    :param critic_x: Critic x model\r\n",
    "    :param critic_x_loss_fn: Critic x loss function\r\n",
    "    :param gradient_penalty_weight: Weight of the gradient penalty\r\n",
    "    :param x_mb: Minibatch of input data\r\n",
    "    :param z: Minibatch of random noise\r\n",
    "    :param valid: Ground truth vector for valid samples\r\n",
    "    :param fake: Ground truth vector for fake samples\r\n",
    "    :param mini_batch_size:\r\n",
    "\r\n",
    "    :return: A tuple containing the total loss and the three single losses\r\n",
    "    \"\"\"\r\n",
    "    # Do a step forward on critic x model and collect gradients\r\n",
    "    x_ = generator(z)\r\n",
    "    fake_x = critic_x(x_)\r\n",
    "    valid_x = critic_x(x_mb)\r\n",
    "\r\n",
    "    # Calculate critic x loss\r\n",
    "    critic_x_valid_cost = critic_x_loss_fn(y_true=valid, y_pred=valid_x)\r\n",
    "    critic_x_fake_cost = critic_x_loss_fn(y_true=fake, y_pred=fake_x)\r\n",
    "    # TODO: [SMe] Is the mini_batch size still required?\r\n",
    "    critic_x_gradient_penalty = critic_x_gradient_penalty(mini_batch_size, x_mb, x_)\r\n",
    "    critic_x_total_loss = critic_x_valid_cost + critic_x_fake_cost + (critic_x_gradient_penalty * gradient_penelty_weight)\r\n",
    "\r\n",
    "    return critic_x_total_loss, critic_x_valid_cost, critic_x_fake_cost, critic_x_gradient_penalty\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def critic_z_loss(encoder , critic_z, critic_z_loss_fn, gradient_penelty_weight,x_mb, z, valid, fake, mini_batch_size):\r\n",
    "    \"\"\"\r\n",
    "    Do a step forward and calculate the loss on the critic z model\r\n",
    "\r\n",
    "    :param encoder: Encoder model\r\n",
    "    :param critic_z: Critic z model\r\n",
    "    :param critic_z_loss_fn: Critic z loss function\r\n",
    "    :param gradient_penalty_weight: Weight of the gradient penalty\r\n",
    "    :param x_mb: Minibatch of input data\r\n",
    "    :param z: Minibatch of random noise\r\n",
    "    :param valid: Ground truth vector for valid samples\r\n",
    "    :param fake: Ground truth vector for fake samples\r\n",
    "    :param mini_batch_size:\r\n",
    "\r\n",
    "    :return: A tuple containing the total loss and the three single losses\r\n",
    "    \"\"\"\r\n",
    "    # Do a step forward on critic z model and collect gradients\r\n",
    "    z_ = encoder(x_mb)\r\n",
    "    fake_z = critic_z(z_)\r\n",
    "    valid_z = critic_z(z)\r\n",
    "\r\n",
    "    # Calculate critic z loss\r\n",
    "    critic_z_valid_cost = critic_z_loss_fn(y_true=valid, y_pred=valid_z)\r\n",
    "    critic_z_fake_cost = critic_z_loss_fn(y_true=fake, y_pred=fake_z)\r\n",
    "    critic_z_gradient_penalty = critic_z_gradient_penalty(mini_batch_size, z, z_)\r\n",
    "    critic_z_total_loss = critic_z_valid_cost + critic_z_fake_cost + (critic_z_gradient_penalty * gradient_penelty_weight)\r\n",
    "    return critic_z_total_loss, critic_z_valid_cost, critic_z_fake_cost, critic_z_gradient_penalty\r\n",
    "\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def encoder_generator_loss(generator , encoder , critic_x , critic_z , encoder_generator_loss_fn , x_mb, z, valid):\r\n",
    "    \"\"\"\r\n",
    "    Do a step forward and calculate the loss on the encoder-generator model\r\n",
    "\r\n",
    "    :param generator: Generator model\r\n",
    "    :param encoder: Encoder model\r\n",
    "    :param critic_x: Critic x model\r\n",
    "    :param critic_z: Critic z model\r\n",
    "    :param encoder_generator_loss_fn: Encoder-generator loss function\r\n",
    "    :param x_mb: Minibatch of input data\r\n",
    "    :param z: Minibatch of random noise\r\n",
    "    :param valid: Ground truth vector for valid samples\r\n",
    "\r\n",
    "    :return: A tuple containing the total loss and the three single losses\r\n",
    "    \"\"\"\r\n",
    "    # Do a step forward on the encoder generator model\r\n",
    "    x_gen_ = generator(z)\r\n",
    "    fake_gen_x = critic_x(x_gen_)\r\n",
    "\r\n",
    "    z_gen_ = encoder(x_mb)\r\n",
    "    x_gen_rec = generator(z_gen_)\r\n",
    "    fake_gen_z = critic_z(z_gen_)\r\n",
    "\r\n",
    "    # Calculate encoder generator loss\r\n",
    "    encoder_generator_fake_gen_x_cost = encoder_generator_loss_fn(y_true=valid, y_pred=fake_gen_x)\r\n",
    "    encoder_generator_fake_gen_z_cost = encoder_generator_loss_fn(y_true=valid, y_pred=fake_gen_z)\r\n",
    "\r\n",
    "    # Use simple MSE as reconstruction error\r\n",
    "    general_reconstruction_cost = tf.reduce_mean(tf.square((x_mb - x_gen_rec)))\r\n",
    "    encoder_generator_total_loss = encoder_generator_fake_gen_x_cost + encoder_generator_fake_gen_z_cost + (10.0 * general_reconstruction_cost)\r\n",
    "\r\n",
    "    return encoder_generator_total_loss, encoder_generator_fake_gen_x_cost, encoder_generator_fake_gen_z_cost, general_reconstruction_cost\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Training step for the model </h1>\r\n",
    "- do training step for the critics , encoder and generator\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "@tf.function\r\n",
    "def train_step(input, n_iterations_critic,encoder, generator,critic_x , critic_z) -> dict:\r\n",
    "    \"\"\"\r\n",
    "    Custom training step for this Subclassing API Keras model.\r\n",
    "    The shape should be (n_iterations_critic * batch size, n_channels) because the critic networks are trained\r\n",
    "    multiple times over the encoder-generator network.\r\n",
    "\r\n",
    "    :param X: Group of mini batches that are used to train the critics and the encoder-generator network\r\n",
    "                Shape: (batch_size, signal_length, n_channels)\r\n",
    "    :param n_iterations_critic: Number of iterations to train the critic network\r\n",
    "    :param critic_x_loss: Critic x loss function\r\n",
    "    :param critic_z_loss: Critic z loss function\r\n",
    "    :param encoder_generator_loss: Encoder-generator loss function\r\n",
    "    :param critic_x_optimizer: Critic x optimizer\r\n",
    "    :param critic_z_optimizer: Critic z optimizer\r\n",
    "\r\n",
    "\r\n",
    "    :return: Sub-model losses as los dict\r\n",
    "    \"\"\"\r\n",
    "    # Get the input data\r\n",
    "    X = input[0] if isinstance(input , tuple) else input\r\n",
    "    batch_size = X.shape[0]\r\n",
    "    minibatch_size = batch_size//n_iterations_critic\r\n",
    "    critic_x_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    critic_z_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    encoder_generator_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    encoder_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "    critic_x_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "    critic_z_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "\r\n",
    "\r\n",
    "    #prepare ground truth data\r\n",
    "    valid = tf.ones((minibatch_size, 1))\r\n",
    "    fake = tf.ones((minibatch_size, 1))\r\n",
    "\r\n",
    "    critic_x_loss_steps = []\r\n",
    "    critic_z_loss_steps = []\r\n",
    "\r\n",
    "    for critic_train_steps in range(n_iterations_critic):\r\n",
    "        z = tf.random.normal((minibatch_size, latent_dim, 1))\r\n",
    "        x_mb = X[critic_train_steps * minibatch_size:(critic_train_steps + 1) * minibatch_size]\r\n",
    "\r\n",
    "        #optimize step on critic x model\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            _critic_x_losses = critic_x_loss(encoder, generator, critic_x, critic_x_loss_fn, x_mb, z, valid, fake, minibatch_size)\r\n",
    "\r\n",
    "        #backward step on critic x model\r\n",
    "        critic_x_gradient = tape.gradient(_critic_x_losses[0], critic_x.trainable_variables)\r\n",
    "        critic_x_optimizer.apply_gradients(zip(critic_x_gradient, critic_x.trainable_variables))\r\n",
    "\r\n",
    "        _critic_x_losses = np.array(_critic_x_losses)\r\n",
    "        critic_x_loss_steps.append(_critic_x_losses)\r\n",
    "\r\n",
    "\r\n",
    "        #optimize step on critic z model\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            _critic_z_losses = critic_z_loss(encoder , critic_z , critic_z_loss_fn, gradient_penalty_weight , x_mb, z, valid, fake, minibatch_size)\r\n",
    "\r\n",
    "        #backward step on critic z model\r\n",
    "        critic_z_gradient = tape.gradient(_critic_z_losses[0], critic_z.trainable_variables)\r\n",
    "        critic_z_optimizer.apply_gradients(zip(critic_z_gradient, critic_z.trainable_variables))\r\n",
    "\r\n",
    "        _critic_z_losses = np.array(_critic_z_losses)\r\n",
    "        critic_z_loss_steps.append(_critic_z_losses)\r\n",
    "\r\n",
    "    #optimize step on encoder-generator model\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        #step forward for the generator model\r\n",
    "        _encoder_generator_losses = encoder_generator_loss(generator, encoder, critic_x, critic_z, encoder_generator_loss_fn, X, z, valid)\r\n",
    "\r\n",
    "    #backward step on encoder-generator model\r\n",
    "    encoder_generator_gradient = tape.gradient(_encoder_generator_losses, encoder.trainable_variables +  generator.trainable_variables)\r\n",
    "    encoder_generator_optimizer.apply_gradients(zip(encoder_generator_gradient, encoder.trainable_variables + generator.trainable_variables))\r\n",
    "\r\n",
    "\r\n",
    "    critic_x_losses = np.mean(np.array(critic_x_loss_steps), axis=0)\r\n",
    "    critic_z_losses = np.mean(np.array(critic_z_loss_steps), axis=0)\r\n",
    "    encoder_generator_losses = np.array(_encoder_generator_losses)\r\n",
    "\r\n",
    "    if log_all_losses:\r\n",
    "        return {\r\n",
    "            \"Cx_total\": critic_x_losses[0],\r\n",
    "            \"Cx_valid\": critic_x_losses[1],\r\n",
    "            \"Cx_fake\": critic_x_losses[2],\r\n",
    "            \"Cx_gp_penalty\": critic_x_losses[3],\r\n",
    "\r\n",
    "            \"Cz_total\": critic_z_losses[0],\r\n",
    "            \"Cz_valid\": critic_z_losses[1],\r\n",
    "            \"Cz_fake\": critic_z_losses[2],\r\n",
    "            \"Cz_gp_penalty\": critic_z_losses[3],\r\n",
    "\r\n",
    "            \"EG_total\": encoder_generator_losses[0],\r\n",
    "            \"EG_fake_gen_x\": encoder_generator_losses[1],\r\n",
    "            \"EG_fake_gen_z\": encoder_generator_losses[2],\r\n",
    "            \"G_rec\": encoder_generator_losses[3],\r\n",
    "        }\r\n",
    "    else:\r\n",
    "        return {\r\n",
    "            \"Cx_total\": critic_x_losses[0],\r\n",
    "            \"Cz_total\": critic_z_losses[0],\r\n",
    "            \"EG_total\": encoder_generator_losses[0]\r\n",
    "        }\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "@tf.function\r\n",
    "def test_step(input,encoder , generator , critic_x , critic_z, gradient_penalty_weight):\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    test step for model\r\n",
    "    overrides model.evaluate\r\n",
    "\r\n",
    "    :param input: minibatch of the time series signals (batce_size , signal_length , n_channels)\r\n",
    "    :param critic_x_loss: loss function for critic x\r\n",
    "    :param critic_z_loss: loss function for critic z\r\n",
    "    :param encoder_generator_loss: loss function for encoder and generator\r\n",
    "    :param graident_penalty_weight: penalty weight for gradient\r\n",
    "\r\n",
    "    :return: sub-model losses as loss dict\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    if isinstance(input, tuple):\r\n",
    "            input = input[0]\r\n",
    "\r\n",
    "    batch_size = input.shape[0]\r\n",
    "\r\n",
    "    fake = tf.ones((batch_size , 1))\r\n",
    "    valid = tf.ones((batch_size , 1))\r\n",
    "\r\n",
    "\r\n",
    "    critic_x_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    critic_z_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    encoder_generator_loss_fn = tf.keras.losses.MeanSquaredError()\r\n",
    "    encoder_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "    critic_x_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "    critic_z_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "\r\n",
    "    z = tf.random.normal(shape=(batch_size , latent_dim , 1))\r\n",
    "\r\n",
    "    critic_x_losses = critic_x_loss(generator,critic_x, critic_x_loss_fn ,gradient_penalty_weight , input , z, valid, fake, batch_size)\r\n",
    "    critic_z_losses = critic_z_loss(encoder , critic_z, critic_z_loss_fn, gradient_penalty_weight, input , z, valid, fake, batch_size)\r\n",
    "    encoder_generator_losses = encoder_generator_loss(generator , encoder , critic_x , critic_z , encoder_generator_loss_fn , input , z, valid)\r\n",
    "\r\n",
    "\r\n",
    "    if log_all_losses:\r\n",
    "        loss_dict = {\r\n",
    "            \"Cx_total\": critic_x_losses[0],\r\n",
    "            \"Cx_valid\": critic_x_losses[1],\r\n",
    "            \"Cx_fake\": critic_x_losses[2],\r\n",
    "            \"Cx_gp_penalty\": critic_x_losses[3],\r\n",
    "\r\n",
    "            \"Cz_total\": critic_z_losses[0],\r\n",
    "            \"Cz_valid\": critic_z_losses[1],\r\n",
    "            \"Cz_fake\": critic_z_losses[2],\r\n",
    "            \"Cz_gp_penalty\": critic_z_losses[3],\r\n",
    "\r\n",
    "            \"EG_total\": encoder_generator_losses[0],\r\n",
    "            \"EG_fake_gen_x\": encoder_generator_losses[1],\r\n",
    "            \"EG_fake_gen_z\": encoder_generator_losses[2],\r\n",
    "            \"G_rec\": encoder_generator_losses[3],\r\n",
    "        }\r\n",
    "    else:\r\n",
    "        loss_dict = {\r\n",
    "            \"Cx_total\": critic_x_losses[0],\r\n",
    "            \"Cz_total\": critic_z_losses[0],\r\n",
    "            \"EG_total\": encoder_generator_losses[0]\r\n",
    "        }\r\n",
    "\r\n",
    "    return loss_dict\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "@tf.function\r\n",
    "def call( input, encoder , generator , critic_x , critic_z, **kwargs) -> Tuple[np.array, np.array, np.array, np.array]:\r\n",
    "    \"\"\"\r\n",
    "    Default forward step during the inference step of the model (for training and evaluation see train_step() and test_step()).\r\n",
    "    This function will be called in the model.predict() function to use the trained sub networks for anomaly detection.\r\n",
    "\r\n",
    "    :param X: Batch of signals that should be analyzed by the model (batch_size, signal_length, n_channels)\r\n",
    "\r\n",
    "    :param kwargs: Additional kwargs forwarded to the super class fit method\r\n",
    "\r\n",
    "    :return: Tuple containing the outputs of the sub networks as numpy arrays:\r\n",
    "                - The reconstructed signals from the generator\r\n",
    "                - The compressed embedding of the time series (latent_dim, 1) from the encoder\r\n",
    "                - The fake/real classification result for the reconstructed time series from the critic x network\r\n",
    "                - The fake/real classification result for the learned embedding from the critic z network\r\n",
    "    \"\"\"\r\n",
    "    X = input[0] if isinstance(input , tuple) else input\r\n",
    "    latent_encoding = encoder(X)\r\n",
    "    y_hat = generator(latent_encoding)\r\n",
    "    critic_x = critic_x(X)\r\n",
    "    critic_z = critic_z(latent_encoding)\r\n",
    "    return y_hat, latent_encoding, critic_x, critic_z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Generate the models to be used during training</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "encoder = generate_encoder(ts_input_shape , lstm_units=100)\r\n",
    "generator = generate_generator(latent_dim)\r\n",
    "critic_x = build_critic_x(ts_input_shape)\r\n",
    "critic_z = build_critic_z(latent_dim)\r\n",
    "\r\n",
    "encoder_checkpoint = \"training_checkpoints/encoder-{epoch:04d}.cpkt\"\r\n",
    "generator_checkpoint = \"training_checkpoints/generator-{epoch:04d}.cpkt\"\r\n",
    "critic_x_checkpoint = \"training_checkpoints/ciritic_x-{epoch:04d}.cpkt\"\r\n",
    "critic_z_checkpoint = \"training_checkpoints/critic_z-{epoch:04d}.cpkt\"\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Get the Dataset</h1>\r\n",
    "- create a tf batch dataset out of the CSV\r\n",
    "<br>\r\n",
    "- data should not be shuffeled as the data's sequential information needs to be preserved"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "def pack_features_vector(features, labels):\r\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\r\n",
    "  features = tf.stack(list(features.values()), axis=1)\r\n",
    "  return features, labels\r\n",
    "\r\n",
    "dataset = tf.data.experimental.make_csv_dataset(\"fan_speed_vibration_without_duration.csv\" , batch_size=seq_len)\r\n",
    "#dataset = dataset.shuffle(buffer_size=1024).batch(seq_len)\r\n",
    "\r\n",
    "dataset\r\n",
    "#tf.data.experimental.CsvDataset(\"fan_speed_vibration_without_duration.csv\", [tf.float32 , tf.float32 , tf.float32 . tf.float32, tf.float32 , tf.float32 , tf.float32 . tf.float32])\r\n",
    "\r\n",
    "#dataset = pd.read_csv(\"fan_speed_vibration_without_duration.csv\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: OrderedDict([(signal-1, (100,)), (signal-2, (100,)), (signal-3, (100,)), (signal-4, (100,)), (signal-5, (100,)), (signal-6, (100,)), (signal-7, (100,)), (signal-8, (100,))]), types: OrderedDict([(signal-1, tf.float32), (signal-2, tf.float32), (signal-3, tf.float32), (signal-4, tf.float32), (signal-5, tf.float32), (signal-6, tf.float32), (signal-7, tf.float32), (signal-8, tf.float32)])>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Training the model</h1>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "epoch = 20\r\n",
    "save_dir = \"models/\"\r\n",
    "with trange(epoch , position=0 , unit=\"epoch\") as pbar:\r\n",
    "        for epoch in pbar:\r\n",
    "            pbar.set_description(f\"Epoch {epoch}\")\r\n",
    "            for step , data in enumerate(dataset):\r\n",
    "                data = list(data.values())\r\n",
    "                data = np.array(data)\r\n",
    "                old_shape = data.shape\r\n",
    "                data = data.reshape(old_shape[1] , old_shape[0])\r\n",
    "                print(data.shape)\r\n",
    "                loss_dict = train_step(data, n_iterations_critic , encoder , generator , critic_x , critic_z)\r\n",
    "                pbar.set_postfix(loss_dict , refresh=True)\r\n",
    "            \r\n",
    "            if epoch % 5 == 0:\r\n",
    "                encoder.save_weights(encoder_checkpoint.format(epoch))\r\n",
    "                generator.save_weights(generator_checkpoint.format(epoch))\r\n",
    "                critic_x.save_weights(critic_x_checkpoint.format(epoch))\r\n",
    "                critic_z.save_weights(critic_z_checkpoint.format(epoch))\r\n",
    "                \r\n",
    "        \r\n",
    "        encoder.save(\"models/encoder\")\r\n",
    "        generator.save(\"models/generator\")\r\n",
    "        critic_x.save(\"models/critic_x\")\r\n",
    "        critic_z.save(\"model/critic_z\")\r\n",
    "            \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\615879\\AppData\\Local\\Temp\\1/ipykernel_26020/1427552735.py:45 train_step  *\n        _critic_x_losses = critic_x_loss(encoder, generator, critic_x, critic_x_loss_fn, x_mb, z, valid, fake, minibatch_size)\n    C:\\Users\\615879\\AppData\\Local\\Temp\\1/ipykernel_26020/4111772496.py:19 critic_x_loss  *\n        x_ = generator(z)\n    c:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer encoder_model: expected shape=(None, 100, 8), found shape=(20, 20, 1)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1/ipykernel_26020/2760960974.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mold_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iterations_critic\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcritic_x\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcritic_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_dict\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\615879\\AppData\\Local\\Temp\\1/ipykernel_26020/1427552735.py:45 train_step  *\n        _critic_x_losses = critic_x_loss(encoder, generator, critic_x, critic_x_loss_fn, x_mb, z, valid, fake, minibatch_size)\n    C:\\Users\\615879\\AppData\\Local\\Temp\\1/ipykernel_26020/4111772496.py:19 critic_x_loss  *\n        x_ = generator(z)\n    c:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\Users\\615879\\Desktop\\tadGAN_tf2\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer encoder_model: expected shape=(None, 100, 8), found shape=(20, 20, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "1eca1d2eb7ea6e47c8ed4992ce44e8a18ec8e809e090285b76f916d1c5828f9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}